{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e192655-d0fc-4107-8baa-2440a3ba4f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for inference: cuda\n",
      "======================================================================\n",
      "CODE SECURITY DEEP LEARNING PIPELINE\n",
      "======================================================================\n",
      "Loaded 1359 samples\n",
      "Columns (4 total):\n",
      "  [0]:      import java.security.SecureRandom;\n",
      "     import javax.crypto.Cipher;\n",
      "     import javax.crypto.Ke...\n",
      "  [1]: 4...\n",
      "  [2]: 0...\n",
      "  [3]: 262b6bdf80dd616de599361c5bc2d1a3547a736969ccf6d9f2ff5b94a609c0e2...\n",
      "\n",
      "Auto-detected text column:      import java.security.SecureRandom;\n",
      "     import javax.crypto.Cipher;\n",
      "     import javax.crypto.KeyGenerator;\n",
      "     import javax.crypto.SecretKey;\n",
      "     import javax.crypto.spec.SecretKeySpec;\n",
      "\n",
      "     public class SimpleCrypto {\n",
      "\n",
      "public  String encrypt(String seed, String cleartext) throws Exception {\n",
      "        byte[] rawKey = getRawKey(seed.getBytes());\n",
      "        byte[] result = encrypt(rawKey, cleartext.getBytes());\n",
      "        return toHex(result);\n",
      "}\n",
      "\n",
      "public  String decrypt(String seed, String encrypted) throws Exception {\n",
      "        byte[] rawKey = getRawKey(seed.getBytes());\n",
      "        byte[] enc = toByte(encrypted);\n",
      "        byte[] result = decrypt(rawKey, enc);\n",
      "        return new String(result);\n",
      "}\n",
      "\n",
      "//done\n",
      "private  byte[] getRawKey(byte[] seed) throws Exception {\n",
      "        KeyGenerator kgen = KeyGenerator.getInstance(\"AES\");\n",
      "        SecureRandom sr = SecureRandom.getInstance(\"SHA1PRNG\");\n",
      "        sr.setSeed(seed);\n",
      "    kgen.init(128, sr); // 192 and 256 bits may not be available\n",
      "    SecretKey skey = kgen.generateKey();\n",
      "    byte[] raw = skey.getEncoded();\n",
      "    return raw;\n",
      "}\n",
      "\n",
      "\n",
      "private  byte[] encrypt(byte[] raw, byte[] clear) throws Exception {\n",
      "    SecretKeySpec skeySpec = new SecretKeySpec(raw, \"AES\");\n",
      "        Cipher cipher = Cipher.getInstance(\"AES\");\n",
      "    cipher.init(Cipher.ENCRYPT_MODE, skeySpec);\n",
      "    byte[] encrypted = cipher.doFinal(clear);\n",
      "        return encrypted;\n",
      "}\n",
      "\n",
      "private  byte[] decrypt(byte[] raw, byte[] encrypted) throws Exception {\n",
      "    SecretKeySpec skeySpec = new SecretKeySpec(raw, \"AES\");\n",
      "        Cipher cipher = Cipher.getInstance(\"AES\");\n",
      "    cipher.init(Cipher.DECRYPT_MODE, skeySpec);\n",
      "    byte[] decrypted = cipher.doFinal(encrypted);\n",
      "        return decrypted;\n",
      "}\n",
      "\n",
      "public  String toHex(String txt) {\n",
      "        return toHex(txt.getBytes());\n",
      "}\n",
      "public  String fromHex(String hex) {\n",
      "        return new String(toByte(hex));\n",
      "}\n",
      "\n",
      "public  byte[] toByte(String hexString) {\n",
      "        int len = hexString.length()/2;\n",
      "        byte[] result = new byte[len];\n",
      "        for (int i = 0; i &lt; len; i++)\n",
      "                result[i] = Integer.valueOf(hexString.substring(2*i, 2*i+2), 16).byteValue();\n",
      "        return result;\n",
      "}\n",
      "\n",
      "public  String toHex(byte[] buf) {\n",
      "        if (buf == null)\n",
      "                return \"\";\n",
      "        StringBuffer result = new StringBuffer(2*buf.length);\n",
      "        for (int i = 0; i &lt; buf.length; i++) {\n",
      "                appendHex(result, buf[i]);\n",
      "        }\n",
      "        return result.toString();\n",
      "}\n",
      "private final static String HEX = \"0123456789ABCDEF\";\n",
      "private  void appendHex(StringBuffer sb, byte b) {\n",
      "        sb.append(HEX.charAt((b&gt;&gt;4)&amp;0x0f)).append(HEX.charAt(b&amp;0x0f));\n",
      "}\n",
      "\n",
      "  }\n",
      "\n",
      "Auto-detected label column: 4\n",
      "\n",
      "Class distribution after binary mapping:\n",
      "label\n",
      "0    852\n",
      "1    165\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./local_codebert_model and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26ea96fcc7e47e798d2fb36bf067d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1017 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='306' max='306' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [306/306 03:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Pr Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.418644</td>\n",
       "      <td>0.828431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727473</td>\n",
       "      <td>0.397745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.409180</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.742350</td>\n",
       "      <td>0.375441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.405736</td>\n",
       "      <td>0.789216</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.295082</td>\n",
       "      <td>0.768385</td>\n",
       "      <td>0.383455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DETAILED MODEL EVALUATION\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. CLASSIFICATION REPORT:\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8539    0.8994    0.8761       169\n",
      "           1     0.3462    0.2571    0.2951        35\n",
      "\n",
      "    accuracy                         0.7892       204\n",
      "   macro avg     0.6000    0.5783    0.5856       204\n",
      "weighted avg     0.7668    0.7892    0.7764       204\n",
      "\n",
      "\n",
      "2. CONFUSION MATRIX:\n",
      "----------------------------------------------------------------------\n",
      "[[152  17]\n",
      " [ 26   9]]\n",
      "\n",
      "Accuracy: 0.7892\n",
      "Macro F1: 0.5856, Weighted F1: 0.7764\n",
      "ROC-AUC: 0.7684, PR-AUC: 0.3835\n",
      "Specificity: 0.8994, Sensitivity: 0.2571\n",
      "\n",
      "Saving model to ./code_security_results/final_model\n",
      "Model moved to device: cuda\n",
      "\n",
      "Generating predictions for question_snippets.csv...\n",
      "Loaded 2503 question snippets.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# ---------------------------\n",
    "# Load and preprocess data\n",
    "# ---------------------------\n",
    "def load_data(filepath, text_column=None, label_column=None):\n",
    "    \"\"\"Load CSV file with code snippets and labels\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"Loaded {len(df)} samples\")\n",
    "    print(f\"Columns ({len(df.columns)} total):\")\n",
    "    for i, col in enumerate(df.columns):\n",
    "        print(f\"  [{i}]: {col[:100]}...\")  # Show first 100 chars of column name\n",
    "\n",
    "    # Auto-detect columns if not specified\n",
    "    if text_column is None:\n",
    "        text_column = df.columns[0]\n",
    "        print(f\"\\nAuto-detected text column: {text_column}\")\n",
    "\n",
    "    if label_column is None:\n",
    "        for col in df.columns[1:]:\n",
    "            unique_vals = df[col].dropna().unique()\n",
    "            if len(unique_vals) <= 10 and all(isinstance(v, (int, float, str)) for v in unique_vals):\n",
    "                label_column = col\n",
    "                print(f\"Auto-detected label column: {label_column}\")\n",
    "                break\n",
    "        if label_column is None:\n",
    "            label_column = df.columns[1]\n",
    "            print(f\"Using column {label_column} as label column\")\n",
    "\n",
    "    # Remove NaN values\n",
    "    df_clean = df[[text_column, label_column]].copy()\n",
    "    df_clean = df_clean.dropna()\n",
    "\n",
    "    # Rename columns\n",
    "    df_clean.columns = ['text', 'label']\n",
    "\n",
    "    # Convert label to int\n",
    "    try:\n",
    "        df_clean['label'] = df_clean['label'].astype(int)\n",
    "    except:\n",
    "        unique_labels = df_clean['label'].unique()\n",
    "        print(f\"\\nFound non-numeric labels: {unique_labels}\")\n",
    "        label_map = {label: idx for idx, label in enumerate(sorted(unique_labels))}\n",
    "        print(f\"Mapping: {label_map}\")\n",
    "        df_clean['label'] = df_clean['label'].map(label_map)\n",
    "\n",
    "    # Enforce binary labels (0 = vulnerable, 1 = secure)\n",
    "    # In your data, scores >=3 are insecure (vulnerable), scores <3 are secure.\n",
    "    # So, map 0,1,2 -> 1 (Secure), 3,4 -> 0 (Vulnerable)\n",
    "    df_clean['label'] = df_clean['label'].apply(lambda x: 1 if x < 3 else 0) # Changed mapping\n",
    "\n",
    "    print(f\"\\nClass distribution after binary mapping:\")\n",
    "    print(df_clean['label'].value_counts())\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "# ---------------------------\n",
    "# Compute metrics\n",
    "# ---------------------------\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    probs = torch.softmax(torch.tensor(pred.predictions), dim=-1).numpy()\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(labels, probs[:, 1])\n",
    "    except:\n",
    "        roc_auc = 0.0\n",
    "\n",
    "    try:\n",
    "        pr_auc = average_precision_score(labels, probs[:, 1])\n",
    "    except:\n",
    "        pr_auc = 0.0\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# Detailed evaluation\n",
    "# ---------------------------\n",
    "def detailed_evaluation(trainer, test_dataset, tokenizer, output_dir='./results'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DETAILED MODEL EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    preds = predictions.predictions.argmax(-1)\n",
    "    labels = predictions.label_ids\n",
    "    probs = torch.softmax(torch.tensor(predictions.predictions), dim=-1).numpy()\n",
    "\n",
    "    # Classification report\n",
    "    print(\"\\n1. CLASSIFICATION REPORT:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(classification_report(labels, preds, digits=4))\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(\"\\n2. CONFUSION MATRIX:\")\n",
    "    print(\"-\" * 70)\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    print(cm)\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(labels, preds, average=None)\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(labels, probs[:, 1])\n",
    "    except:\n",
    "        roc_auc = 0.0\n",
    "    try:\n",
    "        pr_auc = average_precision_score(labels, probs[:, 1])\n",
    "    except:\n",
    "        pr_auc = 0.0\n",
    "\n",
    "    # Specificity & Sensitivity\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "    print(f\"Macro F1: {f1_macro:.4f}, Weighted F1: {f1_weighted:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}, PR-AUC: {pr_auc:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}, Sensitivity: {sensitivity:.4f}\")\n",
    "\n",
    "    # Visualizations\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Vulnerable', 'Secure'], yticklabels=['Vulnerable', 'Secure'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(f'{output_dir}/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(labels, probs[:, 1])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.savefig(f'{output_dir}/roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(labels, probs[:, 1])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall_curve, precision_curve, label=f'PR Curve (AUC = {pr_auc:.4f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.savefig(f'{output_dir}/precision_recall_curve.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision_weighted,\n",
    "        'recall': recall_weighted,\n",
    "        'f1': f1_weighted,\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# Train BERT model\n",
    "# ---------------------------\n",
    "def train_bert_model(df, output_dir='./results', model_name='./local_codebert_model'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Ensure the local model path exists\n",
    "    if not os.path.isdir(model_name):\n",
    "        raise FileNotFoundError(f\"Local model directory not found: {model_name}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "    dataset = Dataset.from_pandas(df[['text', 'label']])\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    train_test = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "    train_dataset = train_test['train']\n",
    "    test_dataset = train_test['test']\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        # --- MODIFIED LOGGING ---\n",
    "        logging_dir=f'{output_dir}/logs',\n",
    "        logging_strategy=\"no\", # Disable logging to potentially avoid progress update errors\n",
    "        # logging_steps=50, # Commented out\n",
    "        # --- END MODIFIED LOGGING ---\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='f1',\n",
    "        greater_is_better=True,\n",
    "        save_total_limit=2\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "    trainer.train()\n",
    "\n",
    "    metrics = detailed_evaluation(trainer, test_dataset, tokenizer, output_dir)\n",
    "\n",
    "    print(f\"\\nSaving model to {output_dir}/final_model\")\n",
    "    model.save_pretrained(f'{output_dir}/final_model')\n",
    "    tokenizer.save_pretrained(f'{output_dir}/final_model')\n",
    "\n",
    "    return model, tokenizer, trainer, metrics\n",
    "\n",
    "# ---------------------------\n",
    "# Prediction function (CORRECTED for GPU)\n",
    "# ---------------------------\n",
    "def predict_code_security(model, tokenizer, code_snippet):\n",
    "    # Get the device the model is currently on\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(code_snippet, return_tensors='pt', truncation=True, max_length=512, padding=True)\n",
    "    # Move the input tensors to the same device as the model\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    # Perform prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=-1)\n",
    "        prediction = torch.argmax(probs, dim=-1).item()\n",
    "        confidence = probs[0][prediction].item()\n",
    "\n",
    "    result = \"SECURE\" if prediction == 1 else \"VULNERABLE\"\n",
    "    return result, confidence * 100, probs[0].tolist()\n",
    "\n",
    "# ---------------------------\n",
    "# Generate Predictions for Question Snippets\n",
    "# ---------------------------\n",
    "def generate_predictions_for_questions(model, tokenizer, question_file, output_file):\n",
    "    \"\"\"Generate predictions for snippets in question_file and save to output_file.\"\"\"\n",
    "    print(f\"\\nGenerating predictions for {question_file}...\")\n",
    "\n",
    "    # Load question snippets\n",
    "    df_questions = pd.read_csv(question_file)\n",
    "    print(f\"Loaded {len(df_questions)} question snippets.\")\n",
    "\n",
    "    # Create a new column for predictions\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    prob_vul = []\n",
    "    prob_sec = []\n",
    "\n",
    "    # Assuming the text column is the first one\n",
    "    text_column = df_questions.columns[0]\n",
    "\n",
    "    for snippet in df_questions[text_column]:\n",
    "        result, confidence, probs = predict_code_security(model, tokenizer, snippet)\n",
    "        predictions.append(result)\n",
    "        confidences.append(confidence)\n",
    "        prob_vul.append(probs[0]) # Probability of Vulnerable (class 0)\n",
    "        prob_sec.append(probs[1]) # Probability of Secure (class 1)\n",
    "\n",
    "    # Add predictions to the dataframe\n",
    "    df_questions['prediction'] = predictions\n",
    "    df_questions['confidence'] = confidences\n",
    "    df_questions['prob_vulnerable'] = prob_vul\n",
    "    df_questions['prob_secure'] = prob_sec\n",
    "\n",
    "    # Save to file\n",
    "    df_questions.to_csv(output_file, index=False)\n",
    "    print(f\"Predictions saved to {output_file}\")\n",
    "\n",
    "    return df_questions\n",
    "\n",
    "# ---------------------------\n",
    "# Main function\n",
    "# ---------------------------\n",
    "def main():\n",
    "    TRAINING_FILE = 'answer_snippets.annotations.csv'\n",
    "    QUESTION_FILE = 'question_snippets.csv'\n",
    "    OUTPUT_DIR = './code_security_results'\n",
    "    # Define device explicitly\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device for inference: {DEVICE}\")\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"CODE SECURITY DEEP LEARNING PIPELINE\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Load and prepare training data\n",
    "    df_train = load_data(TRAINING_FILE)\n",
    "\n",
    "    # Train the model\n",
    "    model, tokenizer, trainer, metrics = train_bert_model(df_train, OUTPUT_DIR)\n",
    "\n",
    "    # --- MOVE MODEL TO GPU AFTER TRAINING (CRITICAL FOR PREDICTION) ---\n",
    "    model = model.to(DEVICE)\n",
    "    print(f\"Model moved to device: {DEVICE}\")\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # Generate predictions for question snippets\n",
    "    PREDICTION_OUTPUT_FILE = 'question_snippets.predicts.csv'\n",
    "    df_predictions = generate_predictions_for_questions(model, tokenizer, QUESTION_FILE, PREDICTION_OUTPUT_FILE)\n",
    "\n",
    "    # Optionally, show some sample predictions\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SAMPLE PREDICTIONS ON QUESTION SNIPPETS\")\n",
    "    print(\"=\"*70)\n",
    "    sample_size = min(5, len(df_predictions))\n",
    "    for i in range(sample_size):\n",
    "        snippet = df_predictions.iloc[i][df_predictions.columns[0]]\n",
    "        pred = df_predictions.iloc[i]['prediction']\n",
    "        conf = df_predictions.iloc[i]['confidence']\n",
    "        prob_vul = df_predictions.iloc[i]['prob_vulnerable']\n",
    "        prob_sec = df_predictions.iloc[i]['prob_secure']\n",
    "        print(f\"\\nSnippet {i+1}:\")\n",
    "        print(f\"Text: {snippet[:100]}...\" if len(snippet) > 100 else snippet)\n",
    "        print(f\"Prediction: {pred} (Confidence: {conf:.2f}%)\")\n",
    "        print(f\"Probabilities: Vulnerable={prob_vul:.4f}, Secure={prob_sec:.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PIPELINE COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
